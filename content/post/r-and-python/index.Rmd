---
title: R vs Python â€” Recap of a live stream
author: Amit Levinson
date: '2022-06-03'
slug: r-and-python
categories: [R]
tags: [R, Streaming, Python]
subtitle: 'Questions and answers from the live stream of R vs Python'
summary: 'Answers to seven questions we analyzed using both R and Python on the Dog of Zurich dataset from Kaggle'
featured: yes
image:
  caption: ''
  focal_point: ''
  preview_only: yes
projects: []
draft: true
codefolding_show: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE)
```

```{r echo = FALSE}
library(tidyverse)
library(tidytext)
library(skimr)
library(downloadthis)
```

```{python}
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
```



```{css, echo = FALSE}
newcaption {
  font-size: 0.9em;
  text-align: center;
}
```

A few months ago [Tal Mizrachi](https://www.linkedin.com/in/talnmizrachi/) (The famous [Aanlysis Paralysis](https://www.facebook.com/go.analysis.paralysis)) & I live streamed an R vs/and Python data analysis session. We took the [dogs of Zurich dataset](https://www.kaggle.com/kmader/dogs-of-zurich) cleaned it a bit, added a random DOB column and wrote down a few questions we answered during the live stream.

Besides it being a great experience collobarting with Tal, I think the questions overall touched on various aspects of our data analysis workflows. Hope you enjoy solving the questions and let us know if you liked the stream or came up with a different solution!

#### How should you read this post?

My recommendation would be to **first try solving the questions yourself.** You can find the data-files in the link below:

```{r echo = FALSE}
download_link(
  link = 'https://github.com/AmitLevinson/streaming/raw/main/r_and_python/split_data.zip',
  output_name = "Files from downloadthis",
  button_label = "Download files",
  button_type = "default",
  has_icon = TRUE,
  icon = "fa fa-save",
  self_contained = FALSE
)
```

Great, now that you have the data, answer the following questions with any tool you'd like and as long as it takes you. Once you have the solutions you can check them with our sultions below.

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/watch?v=oO8MZWk07q0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

{{< youtube id="oO8MZWk07q0" >}}

### Questions

  [1. Load the files into memory and combined them into a single Dataframe](#q1) 

  [2. Describe the data using a summary function of sort](#q2)




asda
  
  
asd




###### 1. Load the files into memory and combined them into a single Dataframe {#q1}

**Python <i class="fab fa-python"></i>**

```{python}
all_files = []
for file in os.listdir("split_data/"):
    if not file.endswith("csv"):
        continue
    all_files.append(pd.read_csv("split_data/"+file))

df = pd.concat(all_files, ignore_index=True)

df
```


**R <i class="fab fa-r-project"></i>**

```{r}
files <- paste0("split_data/",list.files(path = "split_data/"))
dogs <- map_dfr(files, read_csv, col_types = cols())

dogs
```

In order to iteratively read the files we create a vector `files` with the relevant paths to all files, and then load them using `map_dfr`. The latter runs `read_csv` on every element of `files`, our data files, and binds the rows together to one dataframe.

###### 2. Describe the data using a summary function of sort {#q2}

**Python <i class="fab fa-python"></i>**

```{python}
df.describe(percentiles=[0.2,0.8])

```


**R <i class="fab fa-r-project"></i>**





