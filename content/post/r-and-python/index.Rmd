---
title: R vs Python — Live Stream Analysis
author: Amit Levinson
date: '2022-06-02'
slug: r-and-python
categories: []
tags: [R, Streaming, Python]
subtitle: 'Questions and answers from the live stream of an R vs Python data analysis'
summary: 'Using both R and Python we answer various questions about the Dog of Zurich dataset. Try it yourself and get some hands-on data analysis practice'
featured: yes
image:
  caption: ''
  focal_point: ''
  preview_only: yes
projects: []
draft: false
codefolding_show: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE)
```


A few months ago [Tal Mizrachi](https://www.linkedin.com/in/talnmizrachi/) (The famous [Analysis Paralysis](https://www.facebook.com/go.analysis.paralysis)) & I [live streamed](https://www.youtube.com/watch?v=oO8MZWk07q0) an R vs Python data analysis session. We took the [dogs of Zurich dataset](https://www.kaggle.com/kmader/dogs-of-zurich), formatted it a bit, added a random DOB column and wrote down a few questions we answered during the live stream, each with his own tool.

Besides it being a great experience collaborating with Tal, I think the questions overall touched on various aspects of our day-to-day data analysis flow. I initially [hosted the questions and answers on a GitHub page](https://amitlevinson.github.io/streaming/r_and_python/index.html) but realized they got lost in the abyss called 'internet'. Instead, I am journalizing it on my website for future me as I pick up Python and others who want to practice their analysis skills. If you liked it, came up with a different solution or just want to share how much you love <s>Python</s> **R**, do reach out to either one of us and let us know. We'd love to hear more about your experience!

### How should you read this post?

My recommendation is to **first try solving the questions yourself.** You can find the data-files in the link below:

```{r echo = FALSE}
library(downloadthis)
download_link(
  link = 'https://github.com/AmitLevinson/streaming/raw/main/r_and_python/split_data.zip',
  output_name = "Files from downloadthis",
  button_label = "Download files",
  button_type = "default",
  has_icon = TRUE,
  icon = "fa fa-save",
  self_contained = FALSE
)
```

Great, now that you have the data, answer the following questions with any tool you'd like. Once you have the solutions you can check them with our solutions below (just click on the question). If you're struggling you can use the output from our answers as a hint before viewing the answer in the code chunks.


### The Questions

  [1. Load the files into memory and combine them into a single Dataframe](#q1) 

  [2. Describe the data using a summary function of sort](#q2)

  [3. What are the top 10 most common colors? Each color should be counted separately, i.e. black/brown should be counted as 1 black, 1 brown.](#q3)  
  
  
  [4. What are the top 10 most common primary breeds by dog gender? Visualize it using a corresponding bar plot](#q4)  
  
  [5. Who (owner) has dogs with the largest age gap between them? What’s the gap value?](#q6)  
  
  [6. Save the Dataframe into an excel file where each sheet is a different age-group of owners](#q7)
  

### The Answers

The following section has the answers to the questions in both Python (by Tal) and R (by me). For each question you'll find the answers in code, an output of the code and a follow up explanation for the R code or procedure we took. The code is collapsed and hidden, so just click to see it. 

<br>


###### 1. Load the files into memory and combine them into a single Dataframe {#q1}

**Python <i class="fab fa-python"></i>**


```{python}
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
```


```{python}
all_files = []
for file in os.listdir("split_data/"):
    if not file.endswith("csv"):
        continue
    all_files.append(pd.read_csv("split_data/"+file))

df = pd.concat(all_files, ignore_index=True)

df
```


**R <i class="fab fa-r-project"></i>**

```{r}
library(tidyverse)
library(tidytext)
library(skimr)
```


```{r}
files <- paste0("split_data/",list.files(path = "split_data/"))
dogs <- map_dfr(files, read_csv, col_types = cols())

dogs
```

In order to read the files we first create a vector called `files` with paths to all the relevant CSVs and load them using `purrr::map_dfr`. The latter runs `read_csv` on every element of `files`, our data file paths, and binds the rows together to one data frame. Basically we iterate across each file path, load it and then combine all of them together to  data frame.

<br>


###### 2. Describe the data using a summary function of sort {#q2}

**Python <i class="fab fa-python"></i>**

```{python}
df.describe(percentiles=[0.2,0.8])

```


**R <i class="fab fa-r-project"></i>**


```{r, results = 'asis'}
skimr::skim(dogs)
```

`skmir::skim` provides a summary of the data by column type. You can also use `summary` and `glimpse`.

<br>


##### 3. What are the top 10 most common colors? Each color should be counted separately, i.e. black/brown should be counted as 1 black, 1 brown {#q3}

**Python <i class="fab fa-python"></i>**


```{python}
melted = df['dog_color'].str.split("/", expand=True).melt().copy()

melted['value'].value_counts()
```


**R <i class="fab fa-r-project"></i>**

```{r}
dogs %>% 
  transmute(
    new_color = strsplit(dog_color, split = "/")
    ) %>% 
  unnest() %>% 
  count(new_color, sort = T)
```

Our color column is comprised of several values in per observation. We `split` the strings to single colors which turns each observation to a list of values (our colors), and we then `unnest` the list and count the colors.  

<br>


##### 4. What are the top 10 most common primary breeds by dog gender? Visualize it using a bar plot {#q4}  

**Python <i class="fab fa-python"></i>**

```{python}
main_table = df[['dog_gender','primary_breed']].pivot_table(index='primary_breed', columns='dog_gender', aggfunc=len).copy()


sorted_by_w = main_table.sort_values('w', ascending=False).head(10).copy()
sorted_by_m = main_table.sort_values('m', ascending=False).head(10).copy()


fig, axes = plt.subplots(1,2)

fig.suptitle("This is a title", fontsize=18)

sorted_by_w.plot(kind='bar', rot=40, color=["pink", "teal"], ax=axes[0], figsize=(20,12))
sorted_by_m.plot(kind='bar', rot=40, color=["pink", "teal"], ax=axes[1], figsize=(20,12))
```



**R <i class="fab fa-r-project"></i>**

```{r}
dogs %>% 
  count(dog_gender, primary_breed, sort = T) %>% 
  group_by(dog_gender) %>% 
  slice(1:10) %>% 
  ggplot(aes(y = reorder_within(primary_breed, by =  n, within = dog_gender), x = n)) +
  geom_col() +
  facet_wrap(vars(dog_gender), scales = "free_y") +
  scale_y_reordered() +
  labs(y = NULL, title = "This is a title")+
  theme_minimal()
```

I start by counting the primary breed within each gender. I then visualize the data with ggplot2, leveraging the `reorder_within`, a function from `tidytext` to reorder the categories within each facet (gender). Alternatively we can remove the `reorder_within` and compare the primary breeds across gender instead of within.

<br>

##### 5. Who (owner) has dogs with the largest age gap between them? What’s the gap value? {#q6}  

**Python <i class="fab fa-python"></i>**


```{python}
df['dog_dob'] = pd.to_datetime(df['dog_dob'])
gb = df[['owner_id', 'dog_dob']].groupby('owner_id').agg([min, max])

gb.columns = ["_".join(list(x)) for x in gb.columns]

gb['diff'] = (gb['dog_dob_max']-gb['dog_dob_min']).dt.days

gb.sort_values('diff').tail(1)
```



**R <i class="fab fa-r-project"></i>**



```{r}
dogs %>% 
  group_by(owner_id) %>% 
  filter(
    n() > 1,
    dog_dob == min(dog_dob) | dog_dob == max(dog_dob)
  ) %>% 
  select(owner_id, dog_dob) %>% 
  arrange(owner_id, dog_dob) %>% 
  summarise(
    timediff = difftime(dog_dob, time2 = lag(dog_dob), units = "days")
  ) %>% 
  fill(timediff, .direction = "up") %>% 
  arrange(-timediff)
```

I start off by filtering to owners having at least two dogs and  take the oldest and youngest dog for each owner. I then arrange the dob within each owner's group, calculate the difference between the ages and arrange by the difference in a descending order, giving us the owner with the largest gap.

During the session [Adi Sarid](https://adisarid.github.io/) suggested another solution, overall more concise and also to my liking. Instead of counting, filtering, etc., he suggests to straight up calculate the age differce between oldest and youngest dog and arrange that in a descending order:

```{r eval = FALSE}
dogs %>% 
  group_by(owner_id) %>% 
  summarise(age_gap = max(dog_dob) - min(dog_dob)) %>% 
  arrange(desc(age_gap))
```

<br>


##### 6. Save the Dataframe into an excel file where each sheet is a different age-group of owners {#q7}


**Python <i class="fab fa-python"></i>**


```{python, eval = FALSE}
writer = pd.ExcelWriter("dogs_by_owner_age_python.xlsx")

for age in df['age'].fillna("None").unique():
    temp_df = df[df['age']==age].copy()
    temp_df.to_excel(writer, sheet_name=age)

writer.save()
```


**R <i class="fab fa-r-project"></i>**


```{r, eval = FALSE}
dogs %>% 
  split(.$age) %>% 
  writexl::write_xlsx(path = "dogs_by_owners_age.xlsx")
```


I really like here the use of `split` that splits a data frame into various lists by the variable passed to it. we can then use that – our object of data frames split by age – and pass it to `write_xlsx` that saves each element of the list as a sheet in our newly written `.xlsx` file.

------

That's it, hope you enjoyed solving the questions. Make sure to checkout the [recording!](https://www.youtube.com/watch?v=oO8MZWk07q0)
