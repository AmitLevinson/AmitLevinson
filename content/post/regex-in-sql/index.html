---
title: Regex and Text Operations in Data Analysis Using Various tools (SQL, R/Python)
aut7hor: Amit Levinson
date: '2022-08-29'
slug: regex-in-sql
categories: []
tags: [R, Python, SQL]
subtitle: 'Learning how to do several string operations with the common data analyst toolbox'
summary: 'Going over various cases of text operations in a data analysis flow, showing how to solve it with SQL compared to R/Python.'
featured: yes
image:
  caption: ''
  focal_point: ''
  preview_only: yes
projects: []
draft: false
codefolding_show: show
editor_options: 
  chunk_output_type: inline
---



<p>Working as a Data Analyst in the fraud domain I constantly find myself manipulating text, mainly for things such as abstracting a pattern we identified. This is done with various text manipulations in SQL or locally in Python or R using regex.</p>
<p>Regex is â€˜a sequence of characters that specifies a search pattern in textâ€™ (~<a href="https://en.wikipedia.org/wiki/Regular_expression">Wikipedia</a>). Basically, we provide a set of rules and guidelines to identify a pattern in the text.</p>
<p>Appreciating the power of Regex and simple text operations in the programs R &amp; Python that I use, doing them in SQL - at lease in MSSQL we currently use - requires adaptations.</p>
<p>In this post Weâ€™ll go over three scenarios I faced in the past, both in some coding language or while using SQL. As Iâ€™ve recently picked up Python Iâ€™ll also solve some of them using that, <strong>but the general idea should be language agnostic, that is using regex and working with text.</strong> Hopefully youâ€™ll learn more about regex and working with text as analysts.</p>
<p>What will we be be looking at?</p>
<ol style="list-style-type: decimal">
<li><p><a href="#lookarounds">Using lookarounds to extract an email domain</a></p></li>
<li><p><a href="#partial-strings">Joining tables with partial matching of values</a></p></li>
<li><p><a href="#separate">Separating text &amp; digits from a string</a></p></li>
</ol>
<div id="setup" class="section level3">
<h3>Setup</h3>
<p>Letâ€™s start by setting up a local connection so we can easily write SQL queries as we move forward:</p>
<pre class="r"><code>library(odbc)
library(DBI)

rconn &lt;- dbConnect(odbc(),
                      Driver = &quot;SQL Server&quot;,
                      Server = &quot;localhost\\SQLEXPRESS&quot;,
                      Database = &quot;regex&quot;)</code></pre>
<p>Awesome, we setup a connection to our local server on the computer and can write explicit SQL queries. As we move forward weâ€™ll be working with both Python (mainly) and a little with R. For that letâ€™s load the relevant libraries and data:</p>
<pre class="python"><code>import pandas as pd

# content/post/regex-in-sql/
payments = pd.read_csv(&#39;data.csv&#39;)</code></pre>
<pre class="r"><code>library(tidyverse)
# content/post/regex-in-sql/
payments &lt;- read_csv(&#39;data.csv&#39;)</code></pre>
<div id="the-data" class="section level5">
<h5>The Data</h5>
<p>Our main dataset is a simple payments table:</p>
<pre class="r"><code>payments</code></pre>
<table>
<colgroup>
<col width="30%" />
<col width="44%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">email</th>
<th align="left">payment_identifier</th>
<th align="left">payment_description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><a href="mailto:johnTheKing2@yahoo.com" class="email">johnTheKing2@yahoo.com</a></td>
<td align="left">4e0fc35a-703f-4ca2-ab4c-57e9824c2e0b</td>
<td align="left">John Dalle 1238127</td>
</tr>
<tr class="even">
<td align="left"><a href="mailto:D234AbJarry@rockingit.it" class="email">D234AbJarry@rockingit.it</a></td>
<td align="left">b7a0879f-b510-442c-b0d1-595e3c7ca4ef</td>
<td align="left">Jarry Cohen 23</td>
</tr>
<tr class="odd">
<td align="left"><a href="mailto:BarbraSA@rockingit.it" class="email">BarbraSA@rockingit.it</a></td>
<td align="left">2459190c-ff94-4d8c-baf8-2fdf15dd2007</td>
<td align="left">Barbra Smith 322</td>
</tr>
<tr class="even">
<td align="left"><a href="mailto:Shawn@gmail.com" class="email">Shawn@gmail.com</a></td>
<td align="left">9954c0d3-fc8f-4234-b77f-20eaaf674841</td>
<td align="left">Shawn Brown 92794</td>
</tr>
<tr class="odd">
<td align="left"><a href="mailto:me@photoshooting.com" class="email">me@photoshooting.com</a></td>
<td align="left">405a073d-44e5-475c-a53f-9541aa578e9d</td>
<td align="left">Dan S. Wilson 283749</td>
</tr>
<tr class="even">
<td align="left"><a href="mailto:Lilly3@gmail.com" class="email">Lilly3@gmail.com</a></td>
<td align="left">6df08994-0335-4463-a921-970f2349413f</td>
<td align="left">Lilly Taylor 3698</td>
</tr>
</tbody>
</table>
<p>The data has 6 rows in total detailing payment transactions: The receiverâ€™s email, the payment identifier (a paymen id) and the payment description containing the receiverâ€™s name and some numbers. If youâ€™re interested in following along or trying yourself see the relevant dataset in the <a href="">websiteâ€™s GitHub repository</a>.</p>
<p>All right then, letâ€™s (^begin|start$)</p>
</div>
</div>
<div id="lookarounds" class="section level3">
<h3>Lookarounds ðŸ‘€ â€” Extracting the domain from an email address</h3>
<p><a href="https://www.regular-expressions.info/lookaround.html">lookarounds</a> are definitely one of my favorite and commonly go-to regex operations. As the name implies, <strong>a lookaround searches for a pattern and specified string in a specific piece of text.</strong> A <em>lookahead</em> searches for the pattern and takes whatâ€™s before it, while a <em>lookbehind</em> searches for the pattern and takes what follows it. They both can be positive or negative, while the former searches for a match (positive match) and the latter searches for the string without a match to the pattern/symbol referenced (negative match).</p>
<p>Letâ€™s explore it with a set of emails. <strong>Say for example you want to extract the email domains, which is everything thatâ€™s after the @ symbol.</strong></p>
<div id="python" class="section level5">
<h5>Python</h5>
<p>Returning to our table, we can do this using the following regex operation:</p>
<pre class="python"><code>(payments
 .loc[:, [&#39;email&#39;]]
 .assign (
   email_domain = payments.email.str.extract(r&#39;((?&lt;=@).+)&#39;) # &lt;- relevant part
 )
)</code></pre>
<pre><code>##                       email       email_domain
## 0    johnTheKing2@yahoo.com          yahoo.com
## 1  D234AbJarry@rockingit.it       rockingit.it
## 2     BarbraSA@rockingit.it       rockingit.it
## 3           Shawn@gmail.com          gmail.com
## 4      me@photoshooting.com  photoshooting.com
## 5          Lilly3@gmail.com          gmail.com</code></pre>
<p>the pattern <code>(?&lt;=@).+</code> essentially extracts any character(s) that follow the @ symbol, in this case our email domain<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. Alternatively if we were interested in extracting email users instead we could use a positive lookahead, looking for the â€˜@â€™ symbol only this time taking whatâ€™s before it (<code>r'(.+(?=@))'</code>). If youâ€™re interested in learning more about lookarounds, check out another post of mine where I extracted <a href="https://amitlevinson.com/blog/automated-plot-with-github-actions/">libraries I used in #TidyTuesday R scripts</a></p>
</div>
<div id="sql" class="section level5">
<h5>SQL</h5>
<p>So how can we do some variation of a lookaround in SQL?</p>
<p>Well, I mainly use it for the positive lookahead/behind, where we can identify the characterâ€™s location and extract anything after it:</p>
<pre class="sql"><code>SELECT DISTINCT email,
  RIGHT(EMAIL, LEN(EMAIL) - CHARINDEX(&#39;@&#39;,EMAIL)) AS email_domain
FROM PAYMENTS p</code></pre>
<div class="knitsql-table">
<table>
<caption><span id="tab:unnamed-chunk-8">Table 1: </span>6 records</caption>
<thead>
<tr class="header">
<th align="left">email</th>
<th align="left">email_domain</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><a href="mailto:BarbraSA@rockingit.it" class="email">BarbraSA@rockingit.it</a></td>
<td align="left">rockingit.it</td>
</tr>
<tr class="even">
<td align="left"><a href="mailto:D234AbJarry@rockingit.it" class="email">D234AbJarry@rockingit.it</a></td>
<td align="left">rockingit.it</td>
</tr>
<tr class="odd">
<td align="left"><a href="mailto:johnTheKing2@yahoo.com" class="email">johnTheKing2@yahoo.com</a></td>
<td align="left">yahoo.com</td>
</tr>
<tr class="even">
<td align="left"><a href="mailto:Lilly3@gmail.com" class="email">Lilly3@gmail.com</a></td>
<td align="left">gmail.com</td>
</tr>
<tr class="odd">
<td align="left"><a href="mailto:me@photoshooting.com" class="email">me@photoshooting.com</a></td>
<td align="left">photoshooting.com</td>
</tr>
<tr class="even">
<td align="left"><a href="mailto:Shawn@gmail.com" class="email">Shawn@gmail.com</a></td>
<td align="left">gmail.com</td>
</tr>
</tbody>
</table>
</div>
<p>Weâ€™re leveraging the function <code>CHARINDEX</code> in order to identify the location of the â€˜@â€™ symbol, and then extract all text from that location forward.</p>
</div>
</div>
<div id="partial-strings" class="section level3">
<h3>Partial string join â€” identifying a string from a partial match</h3>
<p>I wouldnâ€™t say this is a common thing I do, but I had to do it once and was pretty pleased with the solution. Assuming you have another column/dataset with partial matching strings to your primary key, how can you join the two tables?</p>
<p>For example, you received from some partner a list of ids he has for each payment. However, what he has is only a part of the full strings recorded in your system, as we can see below:</p>
<pre class="r"><code>partial_identifiers</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">id</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">b510-442c-b0d1</td>
</tr>
<tr class="even">
<td align="left">fc8f-4234-b77f</td>
</tr>
<tr class="odd">
<td align="left">6df08994-0335-4463-a921</td>
</tr>
</tbody>
</table>
<p>these strings are contained in some of our payment_identifiers, but how can we easily join them considering itâ€™s not an exact match? Weâ€™ll solve it using a join - and not filtering by the pattern - so we can match each identifier to the payment returned.</p>
<div id="r" class="section level5">
<h5>R</h5>
<p>At the time I encountered this I was using mainly R and solved it with that, so letâ€™s go ahead and use that first:</p>
<pre class="r"><code>library(fuzzyjoin)

regex_left_join(x = payments, y = partial_identifiers,
                by = c(&#39;payment_identifier&#39; = &#39;id&#39;)) %&gt;% 
  select(payment_identifier, id)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">payment_identifier</th>
<th align="left">id</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">4e0fc35a-703f-4ca2-ab4c-57e9824c2e0b</td>
<td align="left">NA</td>
</tr>
<tr class="even">
<td align="left">b7a0879f-b510-442c-b0d1-595e3c7ca4ef</td>
<td align="left">b510-442c-b0d1</td>
</tr>
<tr class="odd">
<td align="left">2459190c-ff94-4d8c-baf8-2fdf15dd2007</td>
<td align="left">NA</td>
</tr>
<tr class="even">
<td align="left">9954c0d3-fc8f-4234-b77f-20eaaf674841</td>
<td align="left">fc8f-4234-b77f</td>
</tr>
<tr class="odd">
<td align="left">405a073d-44e5-475c-a53f-9541aa578e9d</td>
<td align="left">NA</td>
</tr>
<tr class="even">
<td align="left">6df08994-0335-4463-a921-970f2349413f</td>
<td align="left">6df08994-0335-4463-a921</td>
</tr>
</tbody>
</table>
<p>I initially had a different answer that basically extracted which values matched as a new column, and then joined on that; But I really like this solution instead as it shows the power of the <a href="https://cran.r-project.org/web/packages/fuzzyjoin/index.html">{fuzzyjoin}</a> R package.</p>
<p>We also do above a left join but moving forward weâ€™ll stay with an inner join, as payments found unmatched wonâ€™t be necessary.</p>
</div>
<div id="python-1" class="section level5">
<h5>Python</h5>
<p>I realized this post solves the other two challenges with Python, so I might as well try it with that too. You know, just for the kicks:</p>
<pre class="python"><code>(payments.merge(partial_identifiers, how = &#39;cross&#39;)
.loc[lambda df: df.apply(lambda row: row[&#39;id&#39;] in row[&#39;payment_identifier&#39;], axis = 1),
    [&#39;payment_identifier&#39;, &#39;id&#39;]]
)</code></pre>
<pre><code>##                       payment_identifier                       id
## 3   b7a0879f-b510-442c-b0d1-595e3c7ca4ef           b510-442c-b0d1
## 10  9954c0d3-fc8f-4234-b77f-20eaaf674841           fc8f-4234-b77f
## 17  6df08994-0335-4463-a921-970f2349413f  6df08994-0335-4463-a921</code></pre>
<p>Itâ€™s a little packed, so letâ€™s break it apart: We first join the two tables using Cartesian product, creating all combinations of payment identifiers and partial strings. The following line goes row by row and checks if the partial string is <code>in</code> the payment identifier. If so, it returns <code>True</code> which is evaluated in the <code>.loc[]</code> argument.</p>
<p>A faster approach (nearly X25 times) instead of the <code>apply</code> would be to filter using list comprehension, but I find it much less readable<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>.</p>
<p>Now letâ€™s turn to SQL and solve it there.</p>
</div>
<div id="sql-1" class="section level5">
<h5>SQL</h5>
<pre class="sql"><code>SELECT TOP 6 payment_identifier,
  pi.id
FROM PAYMENTS p
INNER JOIN partial_identifiers pi
  on p.payment_identifier like concat(&#39;%&#39;, pi.id, &#39;%&#39;)</code></pre>
<div class="knitsql-table">
<table>
<caption><span id="tab:unnamed-chunk-14">Table 2: </span>3 records</caption>
<thead>
<tr class="header">
<th align="left">payment_identifier</th>
<th align="left">id</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">b7a0879f-b510-442c-b0d1-595e3c7ca4ef</td>
<td align="left">b510-442c-b0d1</td>
</tr>
<tr class="even">
<td align="left">9954c0d3-fc8f-4234-b77f-20eaaf674841</td>
<td align="left">fc8f-4234-b77f</td>
</tr>
<tr class="odd">
<td align="left">6df08994-0335-4463-a921-970f2349413f</td>
<td align="left">6df08994-0335-4463-a921</td>
</tr>
</tbody>
</table>
</div>
<p>The idea is pretty straight forward. We can leverage the <code>LIKE</code> operator in a join to do the partial matching for us, matching any payment identifiers to the partial identifiers id.</p>
<p>Interestingly, at the time of facing this challenge at work I started it with R. However, this requried downloading many of the payments and wasnâ€™t easily scalable so eventually I just implemented it using SQL as shown above.</p>
</div>
</div>
<div id="separate" class="section level3">
<h3>Extracting / Separating text &amp; digits.</h3>
<p>Occasionally you might encounter values that contain both a string and digits combined, for example payment descriptions, email users, security answers and more. Being able to separate the text from numbers might be a necessary step for cleaning our data and further analysis.</p>
<p>Letâ€™s see how can we do this on the column payment_description that contains both what seems as a name and a set of numbers.</p>
<div id="python-2" class="section level4">
<h4>Python</h4>
<pre class="python"><code>payments[[&#39;name&#39;, &#39;number&#39;]] = (
  payments.payment_description.str.split(r&#39;(\d+)&#39;, expand = True)
  .iloc[:, 0:2]
)

payments[[&#39;payment_description&#39;, &#39;name&#39;, &#39;number&#39;]]</code></pre>
<pre><code>##     payment_description            name   number
## 0    John Dalle 1238127     John Dalle   1238127
## 1        Jarry Cohen 23    Jarry Cohen        23
## 2      Barbra Smith 322   Barbra Smith       322
## 3     Shawn Brown 92794    Shawn Brown     92794
## 4  Dan S. Wilson 283749  Dan S. Wilson    283749
## 5     Lilly Taylor 3698   Lilly Taylor      3698</code></pre>
<p>itâ€™s pretty straightforward using the python <code>split</code> argument. We pass it a pattern to separate by and wrap it in a parenetheses (so it wonâ€™t drop). From there we just remove an empty column and assign it as new columns into our dataframe.</p>
<p>I donâ€™t show it here but in R we could easily use the <code>tidyr::separate</code> that does exactly that â€“ Separates a string into new columns.</p>
</div>
<div id="sql-2" class="section level4">
<h4>SQL</h4>
<p>This requires a little more work than what we saw, as we want to split it while we varying lengths of numbers across strings:</p>
<pre class="sql"><code>SELECT TOP 6
  Payment_Description,
  REPLACE(TRANSLATE(PAYMENT_DESCRIPTION, &#39;0123456789&#39;,
                                         &#39;##########&#39;),
          &#39;#&#39;,&#39;&#39;) AS Name,
  REPLACE(TRANSLATE(PAYMENT_DESCRIPTION, &#39;abcdefghijklmnopqrstuvwxyz.&#39;,
                                         &#39;###########################&#39;),
          &#39;#&#39;,&#39;&#39;) AS Numbers
FROM PAYMENTS</code></pre>
<div class="knitsql-table">
<table>
<caption><span id="tab:unnamed-chunk-16">Table 3: </span>6 records</caption>
<thead>
<tr class="header">
<th align="left">Payment_Description</th>
<th align="left">Name</th>
<th align="left">Numbers</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">John Dalle 1238127</td>
<td align="left">John Dalle</td>
<td align="left">1238127</td>
</tr>
<tr class="even">
<td align="left">Jarry Cohen 23</td>
<td align="left">Jarry Cohen</td>
<td align="left">23</td>
</tr>
<tr class="odd">
<td align="left">Barbra Smith 322</td>
<td align="left">Barbra Smith</td>
<td align="left">322</td>
</tr>
<tr class="even">
<td align="left">Shawn Brown 92794</td>
<td align="left">Shawn Brown</td>
<td align="left">92794</td>
</tr>
<tr class="odd">
<td align="left">Dan S. Wilson 283749</td>
<td align="left">Dan S. Wilson</td>
<td align="left">283749</td>
</tr>
<tr class="even">
<td align="left">Lilly Taylor 3698</td>
<td align="left">Lilly Taylor</td>
<td align="left">3698</td>
</tr>
</tbody>
</table>
</div>
<p>We combine the <code>TRANSLATE</code> and <code>REPALCE</code> functions to do a string-extract kind of operation. The Translate basically converts any of the characters noted in the second argument to a character in the third argument. We then replace all hashtags to empty values.</p>
<p>This is done both for the name and numbers, converting all letters and a period to empty values, and all numbers to empty values correspondingly.</p>
<p>You usually would have data thatâ€™s a little messier, e.g.Â numbers appearing in between letters, but it should give the main idea and help you start from there (or at least did so for me).</p>
</div>
</div>
<div id="additional-text-operation-tips-in-sql" class="section level3">
<h3>Additional text operation tips in SQL</h3>
<p>Besides the basics you probably know of if youâ€™ve worked in the past with SQL, there were a few other cases where I learned something new. Here are a few last tips before you go:</p>
<ol style="list-style-type: decimal">
<li><p>Though not shown above, you can use regex-like operations and symbols, for example filtering with the <code>WHERE</code> clause a string that is a letter, number, then letter using <code>...Like [a-z][0-9][a-z]</code>.</p></li>
<li><p>In addition, you can use case sensitive operations to match lower and uppercase when needed, just add <code>WHERE column COLLATE Latin1_General_BIN LIKE [A-Z]...</code> to have it case sensitive.</p></li>
<li><p>Some symbols have a designated meaning in SQL, e,g, the <code>%</code> and <code>_</code> operators. But what happens when you want to try and match them? Well, you can use the <code>ESCAPE</code> operator. For example to match sentences that use a â€˜%â€™ symbol you can add any symbol before and escape it: <code>LIKE '%!%% ESCAPE '!'</code>, matching a text with something before and after a â€˜%â€™ sign.</p></li>
</ol>
<p>You can find more more specific tips for text manipulations in MSSQL <a href="https://www.sqlshack.com/t-sql-regex-commands-in-sql-server/">here</a>. Have specific ones in mind that you use daily? Iâ€™d love to hear about them!</p>
</div>
<div id="closing-remarks" class="section level3">
<h3>Closing remarks</h3>
<p>In this blog post we solved three cases using some regex and text manipulations. Sometimes I found myself working with text on the serverâ€™s side, other times working locally with R or Python. <strong>I think itâ€™s mainly knowing that it can be done that gets you most of the way there. The how is just a matter of Googling.</strong></p>
<p>Good luck on your text manipulation endeavours!</p>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>The extra parentheses is to solve the â€˜ValueError: pattern contains no capture groupsâ€™ error, basically including what is it we want to be captured in our regex.<a href="#fnref1" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn2"><p>Itâ€™s acually almost 25 times faster to use list comprehension for filtering (3.28ms vs 79ms, tested on 1,000 rows): <code>.loc[lambda df: [x[0] in x[1] if x[0] is not None else False for x in zip(df['id'], df['payment_identifier'])]</code><a href="#fnref2" class="footnote-back">â†©ï¸Ž</a></p></li>
</ol>
</div>
