---
title: Defining uncertainty in the Israeli lottery
author: Amit Levinson
date: '2020-07-08'
slug: uncertainty-in-the-israeli-lottery
categories: []
tags: [probability]
subtitle: ''
summary: 'Exploring the probability of winning the lottery at and by a given trial with the Geometric distribution'
authors: []
featured: yes
image:
  caption: 'Image by <a href="https://pixabay.com/users/ChiniGaray-10612456/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3846567">Alejandro Garay</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3846567">Pixabay</a>'
  focal_point: ''
  preview_only: yes
projects: []
---



<blockquote>
<p>‚ÄúI have a great idea to get rich. All we need is a lot of money.‚Äù </br> ‚Äï A meme on the internet</p>
</blockquote>
<p>A while ago I was reading about Bernoulli trials and decided that I wanted to explore them further. I was wondering what would be an interesting case study for such a topic, and then it hit me (üí°): Why not explore lottery probabilities? Little did I know that this topic would lead me down the geometric distribution road and help me better grasp the uncertainty in lotteries.</p>
<p><img src="hunger.jpg" width="85%" height="85%" /></p>
<div id="the-rules" class="section level3">
<h3>The rules</h3>
<p>We‚Äôll be exploring the probability of winning the Israeli lottery held by the <a href="https://www.pais.co.il/">Pais organization</a>, a well-known lottery enterprise in Israel. Pais holds their lotteries twice a week with the regular prize of 5 million New Israeli Shekels (NIS), equivalent to $1,420,000. If there‚Äôs no winner for a given week, the prize accumulates to the following lottery. For the sake of the post I‚Äôll only discuss winning a prize, and not focus on the effect of prize increase on when to participate.</p>
<p>When filling out a lottery form you choose 6 numbers in the range of 1‚Äì37 and a ‚Äòstrong‚Äô number in the range of 1‚Äì7<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. In order to win first place you have to <del>get</del> guess correctly both the 6 number set and the strong number. Luckily, the order of the 6 numbers doesn‚Äôt matter therefore if you wrote <span class="math inline">\(6,12...n\)</span> or <span class="math inline">\(12,6,...n\)</span> your good on both (Also known as combinations, more on that in a minute).</p>
<p>Another ‚Äòluck‚Äô in our favor is that in each lottery ticket we have the option to fill out two sets of numbers, therefore doubling our odds of winning. I‚Äôm assuming we‚Äôre on the same page and you won‚Äôt use both of your attempts to guess the same sets of numbers, so that somewhat increases our odds of winning. Speaking of odds, let‚Äôs have a look at them.</p>
</div>
<div id="the-odds" class="section level3">
<h3>The odds</h3>
<p>To understand the lottery probabilities, we need to calculate <strong>the probability of guessing a combination of 6 numbers out of 37 options along with one strong number out of 7 possible numbers.</strong> In order to do this, we can turn to combinations:</p>
<blockquote>
<p>In mathematics, a combination is a selection of items from a collection, such that (unlike permutations) the order of selection does not matter. </br> ‚Äï <a href="https://en.wikipedia.org/wiki/Combination">Wikipedia</a></p>
</blockquote>
<p>That‚Äôs exactly what we need. We want to calculate the probability of randomly guessing six numbers regardless of their order; If the order was important we‚Äôd want to look at permutations. In addition, each number is drawn without replacement, and therefore there can‚Äôt be repetition of the same number.</p>
<p>The formula to calculate combinations is as follows: <span class="math inline">\(C(n,k) = \frac{n!}{k!(n-k)!}\)</span> Where <span class="math inline">\(n\)</span> is the number of options to choose from and <span class="math inline">\(k\)</span> is the number of choices we make.</p>
<p>Inputting our numbers we get <span class="math inline">\(C(37,6) = \frac{37!}{6!(37-6)!}\)</span>, and now we just calculate away. However, don‚Äôt forget we also need to guess another number out of 7 possible numbers (the strong one), so we‚Äôll multiply our outcome by <span class="math inline">\(\frac1 7\)</span>, yielding a probability of <span class="math inline">\(p = \frac{1}{16273488}\)</span>. ‚ÄòLuckily‚Äô we choose two sets of numbers in a given ticket, so we multiply the probability by 2.</p>
<p>Therefore, the probability of winning the lottery is <strong><span class="math inline">\(p = \frac{1}{8136744}\)</span>.</strong></p>
<p>Wow! that‚Äôs a very low probability. How low? Let‚Äôs try and visualize it.</p>
<p>Sometimes when we receive a probability it‚Äôs hard to grasp the odds and numbers thrown at us. Therefore, I‚Äôll try to visualize it for us. Imagine there‚Äôs a pool filled with 8,136,744 balls. One of those balls is red and choosing that exact red ball blindly will win you the lottery:</p>
<pre class="r"><code>library(ggplot2)
library(dplyr)
library(scattermore)
library(extrafont)
library(ggtext)

set.seed(123)

df_viz &lt;- data.frame(x = rnorm(8136743, mean = 1000, sd = 1000),y = rnorm(8136743))
point_highlight &lt;- data.frame(x = -1811.674, y = -2.268505588)

lot_p &lt;- ggplot()+
  geom_scattermost(df_viz, pointsize = 0.1, pixels = c(2000,2000))+
  geom_point(data = point_highlight, aes(x = x, y = y), size = 0.3, color = &quot;red&quot;)+
  annotate(geom = &quot;curve&quot;, x = -2750, xend = -1860, y = -3.10, yend = -2.29,
    curvature = -.2, color = &quot;grey25&quot;, size = 0.75, arrow = arrow(length = unit(1.5, &quot;mm&quot;)))+
  annotate(&quot;text&quot; ,x = -2750, y = -3.30, label = &quot;Winner&quot;, family = &quot;Roboto Condensed&quot;, size = 3)+
  labs(title = &quot;Winning the Israeli lottery&quot;, subtitle = &quot;To win, imagine trying to randomly choose a &lt;b&gt;&lt;span style=&#39;color:red&#39;&gt;specific ball&lt;/span&gt;&lt;/b&gt; out of 8,136,744 balls&quot;)+
  theme_void()+
  theme(text = element_text(family = &quot;Roboto Condensed&quot;),
        plot.title.position = &quot;plot&quot;,
        plot.title = element_text(size = 16, face= &quot;bold&quot;),
        plot.subtitle = element_markdown(family = &quot;Roboto Condensed&quot;,size = 12))

lot_p</code></pre>
<p><img src="/post/uncertainty-in-the-israeli-lottery/index_files/figure-html/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Not easy is it?</p>
<p>Now that we know the probability of winning at each attempt, let‚Äôs see how it manifests across multiple attempts.</p>
</div>
<div id="multiple-attempts---geometric-distribution" class="section level3">
<h3>Multiple attempts - Geometric distribution</h3>
<p>A Bernoulli trial is a random experiment with exactly two outcomes - such as success\failure, heads\tails - in which the probability for each outcome is the same every time <a href="https://en.wikipedia.org/wiki/Bernoulli_trial">(Wikipedia)</a>. This sets the ground for discussing an outcome of a lottery in which you either win or lose.</p>
<p>But we want to learn more about the <em>distribution of attempts</em>, and this brings us to the geometric distribution. A <a href="https://en.wikipedia.org/wiki/Geometric_distribution">Geometric distribution</a> enables us to calculate the probability distribution of a number of failures before the first success<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>.</p>
<p>Before we begin, we must meet several conditions to use the geometric distribution:</p>
<p>‚úîÔ∏è Each trial is independent from one another - succeeding in one trial doesn‚Äôt affect the next trial. We know this is true since winning in one lottery won‚Äôt affect your chances of winning the next round.</p>
<p>‚úîÔ∏è Every trial has an outcome of a success or failure. This assumption is true in our case where each lottery you participate in you either win or lose.</p>
<p>‚úîÔ∏è The probability of success <span class="math inline">\(p\)</span> is the same every trial - This is also true given the lottery probabilities are consistent across each game.</p>
<p>Now that we got the technicalities out of the way we can start exploring some of the uncertainty surrounding the lottery.</p>
<div id="winning-at-a-given-trial" class="section level4">
<h4>Winning <strong>at</strong> a given trial</h4>
<p>We can denote the probability of winning as <span class="math inline">\(p\)</span>, which in the case of a lottery game is equal to <span class="math inline">\(p = \frac{1}{8136744}\)</span>. What if we wanted to know the probability of winning the lottery on the third try? That means we need two failures and then a success. If the probability of success - guessing the correct numbers - is <span class="math inline">\(p = \frac{1}{8136744}\)</span>, so the probability of a failure is <span class="math inline">\(q = 1 - p\)</span>, in this case <span class="math inline">\(q = \frac{8136743}{8136744}\)</span>. In order to win the lottery on the third try, this means getting two failures and then a success, resulting in a total of <span class="math inline">\(k = 3\)</span> attempts. Thus, the probability of winning on the third attempt is as follows:</p>
<p><span class="math inline">\(p(3) = (\frac{8136743}{8136744})\cdot(\frac{8136743}{8136744})\cdot(\frac{1}{8136744})\)</span>, equaling <span class="math inline">\(p = 0.0000001228993\)</span>. In other words there‚Äôs a ~0.0000123% chance we‚Äôll win the lottery <em>exactly</em> on the third try.</p>
<p><strong>Generalizing, the probability distribution of the number of Bernoulli trials needed to get one success on the <span class="math inline">\(k\)</span> th trial is: <span class="math inline">\(P(X = k) = (1 - p)^{(k-1)} \cdot p\)</span>.</strong> We can break this up according to our previous example:</p>
<ul>
<li><p><span class="math inline">\(P\)</span> stands for the probability of getting our value <span class="math inline">\(X\)</span> on the <span class="math inline">\(k\)</span> attempt. Meaning, we want to win the lottery only on the third attempt.</p></li>
<li><p>So our first two attempts should be a failure, thus a probability of <span class="math inline">\(q = 1 - \frac{1}{8136744}\)</span> multiplied by two (two rounds of failures), written as <span class="math inline">\((\frac{8136743}{8136744})^{3 - 1}\)</span>.</p></li>
<li><p>Lastly, <span class="math inline">\(p\)</span> stands for the probability of succeeding, <span class="math inline">\(\frac{1}{8136744}\)</span> occurring exactly on the <span class="math inline">\(k\)</span> attempt.</p></li>
</ul>
<p>The probability we just discussed is also known as the probability mass function (PMF) of the geometric distribution. PMF is a function that gives the probability that a random discrete variable is exactly equal to some value. In our above example, the probability that we‚Äôll win exactly on the third try.</p>
</div>
<div id="winning-by-a-given-trial" class="section level4">
<h4>Winning <strong>by</strong> a given trial</h4>
<p>We don‚Äôt necessarily want to win the lottery on on a specific <span class="math inline">\(X\)</span> attempt, but explore the probabilities of winning <em>by</em> the <span class="math inline">\(k\)</span>th attempt. Reframing our previous question we can ask <strong>‚Äúwhat is the probability of winning the lottery on the first 3 attempts?‚Äù</strong>, bringing us to the Cumulative distribution function (CDF). In a cumulative distribution we calculate the probability that <span class="math inline">\(X\)</span> will take a value less than or equal to <span class="math inline">\(k\)</span> (in our case representing the number of attempts).</p>
<p><strong>How does this question change our calculation?</strong></p>
<p>Let‚Äôs assume we‚Äôre still talking about 3 attempts. Our new framed question means we want to win the lottery either on the first attempt, the second or the third. In other words, we want to add the probability of success when <span class="math inline">\(P(X = 1)\)</span> + <span class="math inline">\(P(X = 2)\)</span> + <span class="math inline">\(P(X = 3)\)</span>. Given that our probability of failure is <span class="math inline">\(q = 1 - p\)</span>, we can write the argument as follows: <span class="math inline">\(P(X \leq 3) = q^0\cdot p + q^1 \cdot p + q^2 \cdot p\)</span>, inputting our values of <span class="math inline">\({(\frac{8136743}{8136744}})^0 \cdot p \cdot({\frac{8136743}{8136744}})^1\cdot p, ...\)</span>, resulting in the probability of winning in one of the first three attempts <span class="math inline">\(P(X \leq 3) = 0.000000368\)</span>, also written as a 0.0000368% chance.</p>
<p>But if we want to look at the first 50 attempts? we‚Äôll have to sum each individual PMF?</p>
<p>Here‚Äôs exactly the use of the geometric CDF written as <span class="math inline">\(P(X &lt;= x) = 1 - q^x\)</span>. We power the probability of loosing by the threshold of attempts to win by and deduct it from 1, resulting in the probability of winning by a given trial.</p>
</div>
</div>
<div id="winning-on-the-first-x-trials" class="section level3">
<h3>Winning on the first X trials</h3>
<p>We just looked at the probability of winning on the first 3 trials, and now that we learned about the CDF we can calculate the probability of winning on the first <span class="math inline">\(x\)</span> trials, for e.g.¬†on the first 100, 1000 and so on. In addition, another important factor we can take into account exploring the cumulative distribution is the money spent reaching each attempt.</p>
<p>We‚Äôll start by declaring our values. We know the probability for winning the lottery <em>with each ticket we have</em> is <span class="math inline">\(p = \frac{1}{8,136,744}\)</span> (remember, we get to choose two sets of numbers in each ticket), so let‚Äôs declare that:</p>
<pre class="r"><code>p &lt;- 1/8136744</code></pre>
<p>Next we know the probability for not winning is <span class="math inline">\(q = 1 - p\)</span>:</p>
<pre class="r"><code>q &lt;- 1 - p</code></pre>
<p>Now we can create a data frame to account for some 250,000 attempts. We don‚Äôt need each attempt so we‚Äôll simulate data for the first 50,000 and then have points spread out in a 500 interval jump all the way to the 100,000,000 attempt.</p>
<pre class="r"><code>df_prob &lt;- tibble(trial = c(1:50000, seq(50000, 1e8, 500)))</code></pre>
<p>Once we have that we can calculate both the probability of winning up to a specific attempt and the cumulative amount of money spent reaching there:</p>
<pre class="r"><code>df_prob &lt;- df_prob %&gt;% 
  mutate(cdf = 1 - (1 - p)^trial,
         money_spent = trial * 5.8)

head(df_prob)</code></pre>
<pre><code>## # A tibble: 6 x 3
##   trial         cdf money_spent
##   &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
## 1     1 0.000000123         5.8
## 2     2 0.000000246        11.6
## 3     3 0.000000369        17.4
## 4     4 0.000000492        23.2
## 5     5 0.000000614        29  
## 6     6 0.000000737        34.8</code></pre>
<p>Looks good!</p>
<p>We see our top 6 observations with 3 columns we just defined (from left to right): the lottery raffle (trial), the probability of winning at a given trial until that point (cdf) and the money spent by that trial. Our probability of winning at <em>any</em> trial is constant (<span class="math inline">\(p\)</span>), so it‚Äôll be redundant to add that in here.</p>
<p>Now let‚Äôs look at specific points along our data frame and see how much money is spent reaching there. More specifically, let‚Äôs look at the details of some attempts such as 1; 10; 100; 1000; 2500, 5000, <span class="math inline">\(...\)</span>, 1,000,000, 10,000,000; 50,000,000:</p>
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#hvuocxzswv .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#hvuocxzswv .gt_heading {
  background-color: #FFFFFF;
  text-align: left;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#hvuocxzswv .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#hvuocxzswv .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#hvuocxzswv .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#hvuocxzswv .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#hvuocxzswv .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#hvuocxzswv .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#hvuocxzswv .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#hvuocxzswv .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#hvuocxzswv .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#hvuocxzswv .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#hvuocxzswv .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#hvuocxzswv .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#hvuocxzswv .gt_from_md > :first-child {
  margin-top: 0;
}

#hvuocxzswv .gt_from_md > :last-child {
  margin-bottom: 0;
}

#hvuocxzswv .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#hvuocxzswv .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#hvuocxzswv .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#hvuocxzswv .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#hvuocxzswv .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#hvuocxzswv .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#hvuocxzswv .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#hvuocxzswv .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#hvuocxzswv .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#hvuocxzswv .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#hvuocxzswv .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#hvuocxzswv .gt_left {
  text-align: left;
}

#hvuocxzswv .gt_center {
  text-align: center;
}

#hvuocxzswv .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#hvuocxzswv .gt_font_normal {
  font-weight: normal;
}

#hvuocxzswv .gt_font_bold {
  font-weight: bold;
}

#hvuocxzswv .gt_font_italic {
  font-style: italic;
}

#hvuocxzswv .gt_super {
  font-size: 65%;
}

#hvuocxzswv .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
</style>
<div id="hvuocxzswv" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;"><table class="gt_table">
  <thead class="gt_header">
    <tr>
      <th colspan="3" class="gt_heading gt_title gt_font_normal" style><b><span style='font-family:Roboto Condensed'>Lottery probabilities with the geometric distribution</span></b></th>
    </tr>
    <tr>
      <th colspan="3" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border" style><span style='font-family:Roboto Condensed'>Lottery probabilities winning by a given attempt, the money spent reaching there and your chances of winning by then</span></th>
    </tr>
  </thead>
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Attempt</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Money spent<sup class="gt_footnote_marks">1</sup></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">% winning by then</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr>
      <td class="gt_row gt_left">1</td>
      <td class="gt_row gt_left">$2</td>
      <td class="gt_row gt_left">0.00001%</td>
    </tr>
    <tr>
      <td class="gt_row gt_left">10</td>
      <td class="gt_row gt_left">$17</td>
      <td class="gt_row gt_left">0.00012%</td>
    </tr>
    <tr>
      <td class="gt_row gt_left">100</td>
      <td class="gt_row gt_left">$166</td>
      <td class="gt_row gt_left">0.00123%</td>
    </tr>
    <tr>
      <td class="gt_row gt_left">500</td>
      <td class="gt_row gt_left">$829</td>
      <td class="gt_row gt_left">0.00614%</td>
    </tr>
    <tr>
      <td class="gt_row gt_left">1,000</td>
      <td class="gt_row gt_left">$1,657</td>
      <td class="gt_row gt_left">0.01229%</td>
    </tr>
    <tr>
      <td class="gt_row gt_left">2,500</td>
      <td class="gt_row gt_left">$4,143</td>
      <td class="gt_row gt_left">0.03072%</td>
    </tr>
    <tr>
      <td class="gt_row gt_left">5,000</td>
      <td class="gt_row gt_left">$8,286</td>
      <td class="gt_row gt_left">0.06143%</td>
    </tr>
    <tr>
      <td class="gt_row gt_left">10,000</td>
      <td class="gt_row gt_left">$16,571</td>
      <td class="gt_row gt_left">0.12282%</td>
    </tr>
    <tr>
      <td class="gt_row gt_left">25,000</td>
      <td class="gt_row gt_left">$41,429</td>
      <td class="gt_row gt_left">0.30678%</td>
    </tr>
    <tr>
      <td class="gt_row gt_left">100,000</td>
      <td class="gt_row gt_left">$165,714</td>
      <td class="gt_row gt_left">1.22147%</td>
    </tr>
    <tr>
      <td class="gt_row gt_left">250,000</td>
      <td class="gt_row gt_left">$414,286</td>
      <td class="gt_row gt_left">3.02576%</td>
    </tr>
    <tr>
      <td class="gt_row gt_left">500,000</td>
      <td class="gt_row gt_left">$828,571</td>
      <td class="gt_row gt_left">5.95997%</td>
    </tr>
    <tr>
      <td class="gt_row gt_left">1,000,000</td>
      <td class="gt_row gt_left">$1,657,143</td>
      <td class="gt_row gt_left">11.56473%</td>
    </tr>
    <tr>
      <td class="gt_row gt_left">10,000,000</td>
      <td class="gt_row gt_left">$16,571,429</td>
      <td class="gt_row gt_left">70.74129%</td>
    </tr>
    <tr>
      <td class="gt_row gt_left">50,000,000</td>
      <td class="gt_row gt_left">$82,857,143</td>
      <td class="gt_row gt_left">99.78557%</td>
    </tr>
  </tbody>
  
  <tfoot>
    <tr class="gt_footnotes">
      <td colspan="3">
        <p class="gt_footnote">
          <sup class="gt_footnote_marks">
            <em>1</em>
          </sup>
           
          Money spent corresponds to the cumulative number of attempts played
          <br />
        </p>
      </td>
    </tr>
  </tfoot>
</table></div>
<p>In the above table I printed specific observations along the lottery‚Äôs cumulative geometric distribution. In our left column we have the trial number, next the approximate amount of money spent up to that trial and lastly the percent of winning by that given trial. Notice that I converted the New Israeli Shekels to dollars ($1 dollar = ~ NIS 3.5).</p>
<p>If we played 100 consecutive games with the same number, we would spend 166 dollars by that point and have only a 0.00123% chance of winning. We only pass the 1% (!) chance of winning after buying more than 100,000 tickets, spending a total of $165,714 dollars.<br />
<strong>To pass the 10% chance of winning you‚Äôd have to play 1,000,000 games and spend ~1,600,000 dollars! Remember, the default prize is only some $1,412,000!</strong></p>
<p><img src="dumber.jpg" width="246" height="80%" /></p>
</div>
<div id="average-number-of-attempts" class="section level3">
<h3>Average number of attempts</h3>
<p>An interesting feature of the geometric distribution is that we can calculate the mean and variance of the distribution. The mean in the discussed cumulative distribution is <span class="math inline">\(E(X) = \frac{1}{p}\)</span> and a variance of <span class="math inline">\(var(X) = \frac{1-p}{p^2}\)</span>. The mean is basically the expected value for the number of independent trials needed to get the first success. So in our lottery example the expected number of attempts to reach a success is <span class="math inline">\(E(X) = \frac{1}{\frac{1}{8136744}}\)</span>, resulting in 8,136,744 attempts.</p>
<p>R has built in functions for working with the geometric distribution such as <code>pgeom</code>, <code>rgeom</code>, <code>qgeom</code> and <code>dgeom</code> which you can explore more <a href="https://www.statology.org/dgeom-pgeom-qgeom-rgeom-r/">here</a>. For the purpose of exploring the mean we can use the <code>rgeom</code> function which generates a value representing the number of failures before a success occurred. For example, let‚Äôs see how many failures we‚Äôre required to reach one success:</p>
<pre class="r"><code>rgeom(n = 1,p = p)</code></pre>
<pre><code>## [1] 30687199</code></pre>
<p>In the above example <code>rgeom</code> takes the number of rounds (n = 1) and the probability of winning (p = p). The outputted value indicates the number of failures before our success.</p>
<p>Using this we can calculate the average number of attempts from 2,000,000 games:</p>
<pre class="r"><code>mean(rgeom(2e6, p))</code></pre>
<pre><code>## [1] 8129065</code></pre>
<p>Pretty close to our expected value!</p>
<p>So what does the <span class="math inline">\(E(X)\)</span> mean in terms of the lottery? <strong>On average, you‚Äôd have to play 8,136,744 games to win the lottery, spending a total of NIS 47,193,115 (~$13,483,747) to win approximately NIS 5M (1.42M dollars)!</strong></p>
</div>
<div id="conclusion" class="section level3">
<h3>Conclusion</h3>
<p>In this post we were able to uncover and better understand some of the uncertainty that covers a lottery game. Using the geometric distribution we explored the probability of winning the lottery at a specific event, and winning it in the form of a cumulative distribution - Chances of winning up to a given trial.</p>
<p>Unfortunately, the numbers aren‚Äôt in our favor. You‚Äôd find yourself spending a great deal of money before actually winning the lottery. I‚Äôm definitely not going to tell you what to do with your money, but I hope this blog post helped you grasp a little better the chances of (not) winning the lottery.</p>
</div>
<div id="further-reading-exploring" class="section level3">
<h3>Further reading \ exploring</h3>
<p>Two resources I found extremely valuable in learning more about the geometric distribution:</p>
<ul>
<li><p>The <a href="https://en.wikipedia.org/wiki/Geometric_distribution">Geometric distribution Wikipedia‚Äôs page</a>. I‚Äôm constantly amazed at the vast amount and well articulated statistical pages they have.</p></li>
<li><p>Continuing on that, I found the resource that the Wikipedia page relies on extremely helpful: ‚ÄúA modern introduction to probability and statistics : understanding why and how‚Äù.</p></li>
<li><p>If you‚Äôre more of a video kind of person, I highly recommend a video by <a href="https://www.youtube.com/channel/UCEWpbFLzoYGPfuWUMFPSaoA">The Organic Chemistry Tutor</a> about the <a href="https://www.youtube.com/watch?v=d5iAWPnrH6w&amp;t=1s">Geometric distribution</a>. I think he does a superb job in explaining different various statistical analysis and always enjoys his videos.</p></li>
</ul>
</div>
<div id="notes" class="section level3">
<h3>Notes</h3>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>An amusing anecdote is that the Pais organization offers information about ‚ÄòHot‚Äô numbers and the <a href="https://www.pais.co.il/lotto/statistics.aspx">frequency of appearance for each number</a>. Considering that the lottery is random I wouldn‚Äôt rely on such a pattern‚Ä¶<a href="#fnref1" class="footnote-back">‚Ü©Ô∏é</a></p></li>
<li id="fn2"><p>In this blog post I only explore one aspect of the geometric PMF by looking at number of failures before the first success in a set of <span class="math inline">\(k \in \{0 , 1, 2, ...\}\)</span> attempts. To read more about the PMF I recommend starting with the Wikipedia page of the <a href="https://en.wikipedia.org/wiki/Geometric_distribution">Geometric distribution</a>.<a href="#fnref2" class="footnote-back">‚Ü©Ô∏é</a></p></li>
</ol>
</div>
