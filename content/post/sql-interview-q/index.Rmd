---
title: An SQL interview question to learn from
author: Amit Levinson
date: '2021-08-26'
slug: a-great-sql-questions
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: ''
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: yes
draft: true
projects: []
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

http://sqlfiddle.com/#!9/423702/12


During the first half of 2021, as I was finishing up my M.A. thesis, I started searching for a job in Data Analytics. [My journey into analytics was through learning R](https://amitlevinson.com/blog/my-year-in-r/) and I realized I had to learn some SQL, or at least familiarize myself with it.

Fast forward to interviewing, most of the SQL interview questions were pretty good. There was one question I was really fond of and had thought about it since; this blog post details that question and several answers to it.


**An important caveat: The question and data do not represent my current employer.** The data used here is made up and the question came from a different company. 

Note that I'll be using R to setup an SQL connection in memory but power through the blogpost with SQL. While not necessary, some SQL knowledge is useful to understanding the various answers' syntax.

## The Interview question

So here it goes:

> Let's say you have a table of users' payments. The table has the user's name, date of payment and the amount they received. Users have multiple records with different amounts and dates. For each user return the user name, the maximum amount they received and the date of that payment.

And now for the second part:

> Once you solve that, solve it again using a different approach.

For a more practical example, considering the following raw data:

```{r echo = TRUE}
# library(dbplyr)
library(dplyr)
library(gt)
library(tibble)
library(DBI)
library(keyring)
library(stringr)
library(ggplot2)
library(gt)
library(forcats)
library(dplyr)

```


```{r}
# create the data
payments <- tribble(
  ~username,    ~payment_date,    ~amount,
  "Danny",  "2021-07-05",     42,
  "Danny",  "2021-05-12",     62,
  "Danny",  "2021-08-01",     80,
  "Danny",  "2021-06-12",     87,
  "Alice",  "2021-07-03",     60,
  "Alice",  "2021-05-29",     72,
  "Alice",  "2021-05-12",     85,
  "Alice",  "2021-06-24",     45,
  "Tom",    "2021-06-28",     80,
  "Tom",    "2021-07-12",     56,
  "Tom",    "2021-07-19",     95,
  "Tom",    "2021-05-11",     75
) %>% 
  mutate(payment_date = as.character(payment_date))

# Setup a localhost connection
localhost_con <- dbConnect(RMariaDB::MariaDB(),
                  host = 'localhost',
                  dbname = "sql_interview",
                  username = key_get("mysql-local-user"),
                  password = key_get("mysql-local-password"),
                  port = 3306)

# dbWriteTable(localhost_con, "payments", payments, overwrite = TRUE)
```


```{r, fig.align = 'left'}

# payments %>% clipr::write_clip()

raw_payments <- payments %>% 
  arrange( payment_date)

gt(raw_payments) %>% 
    tab_style(
      style = cell_fill(color = '#90ee90'),
      locations = cells_body (
        rows = c(3,5,11)
      )
    )
```

Return the following table:

```{r, fig.align='center'}
payments %>% 
  group_by(username) %>% 
  filter(amount == max(amount)) %>% 
  ungroup() %>% 
  arrange(username) %>% 
  gt()
```


All right. So we know what we have to do. But before we do it, let's see how not to do it.

### Why not just a simple GROUP BY?

If your new to SQL, an immediate question that might come to mind is why not use a simple `GROUP BY` and return the `MAX` value. I.e., just filter each group by the max value according to one of the variables.  

The issue is when we use `GROUP BY` we retrieve only the information that is aggregated. That is, if we group by the sellers name, and the payment date when we return the max we get the value for each distinct user and date. In other words, all are original values as we can see in the table below:

```{sql connection=localhost_con, echo = TRUE}
SELECT UserName,
  MAX(amount) AS amount
FROM Payments 
GROUP BY UserName
```

Alternatively, if we `GROUP BY` the UserName and `SELECT` the `MAX` value and the date, the result will depend on the Relational database management system (RDBMS) you use. If you're using SQL server you'll get an error as you have a column which is selected but is not contained in an Aggregate function nor in the GROUP BY clause.   

In other RDMBS, e.g. MySQL which I use here, we'll get the information for each User, their max value and some date (here the top date value), **but not the correct one**:

```{sql connection=localhost_con, echo = TRUE}
SELECT UserName,
  payment_date,
  MAX(amount)
FROM payments 
GROUP BY UserName
```


```{sql connection=localhost_con, echo = TRUE}
SELECT UserName,
  Payment_Date,
  max(amount) AS amount
FROM payments
GROUP BY UserName

```

So How do we solve this? Let's dive in.  

<br>

## Solutions

### 1. Window functions

The first solution that might come to mind is using a Window Function. If you don't know them I suggest you familiarize yourself with their abilities. To borrow from [PostgreSQL's description](https://www.postgresql.org/docs/9.1/tutorial-window.html), a window function "performs a calculation across a set of table rows that are somehow related to the current row". In different from aggregate operations (sum, avg, etc), using window functions doesn't cause rows to become grouped into single row outputs.  

We can use the window function [DENSE_RANK()](https://docs.microsoft.com/en-us/sql/t-sql/functions/dense-rank-transact-sql?view=sql-server-ver15)/RANK()[^1] to retrieve the amount's rank within each users observations, and extract the relevant row with an outer query:

[^1]: One reason I'm not going for ROW_NUMBER here is that were interested in the top value that could have multiple appearances for a user. ROW NUMBER will only give us one value, here I'm interested in the max value that could appear several times.

```{sql connection=localhost_con, echo = TRUE}
SELECT UserName, Payment_Date as 'Payment Date', amount
FROM (
  SELECT *,
    DENSE_RANK() OVER(Partition BY UserName Order by amount DESC) as rnk
  FROM payments) AS ranked_table
WHERE rnk = 1;
```

OK, that was pretty straight forward. But the interview question doesn't end there but asks for another approach. Let's move on.

### 2. Self Join

`JOIN` are key functions when querying data. Considering the large amount of data a company has, and the normalization procedures it does you'll be expected to join a lot. In this specific case we can leverage the arithmetic features of a `JOIN` to retrieve the relevant value:


```{sql connection=localhost_con, echo = TRUE}
SELECT DISTINCT p.UserName, p.payment_date, p.amount
FROM payments p
LEFT JOIN payments pp ON p.UserName = pp.UserName
  AND p.amount < pp.amount
WHERE pp.amount IS NULL;


```

While we're all familiar with 'regular' `* JOIN` using equality signs `=`, we can check for other operations such as smaller than `<`. Essentially we do a cartesian join of the table on itself by user, and then filter rows where values (p.amount) are smaller than other values (pp.amount). Our max value won't find any relevant rows to join, considering it's not smaller than anything, which will result with a `NULL` value we can use to filter.  

If you want to see the intermediate step just copy the above code to the snippet example, remove the `WHERE` clause and select all columns.

### 3. Correlated subquery

We've come to my final approach for this blog post. I've come to like Correlated subqueries since learning them, as I find them somewhat similar to vectorized operations in `R` such as the `apply` family and `purrr` library.

A correlated subquery is a row-by-row process, in which each subquery is executed once for the outer query (adapted from [GeeksforGeeks](https://www.geeksforgeeks.org/sql-correlated-subqueries/)). Let's look at the code and answer and explain it more clearly:


```{sql corr-subqeury, connection=localhost_con, echo = TRUE}
SELECT UserName,
  Payment_Date,
  amount
  FROM Payments p
  WHERE amount = (SELECT MAX(amount)
                          FROM Payments pp
                          WHERE pp.UserName = p.UserName -- Notice the relation to the parent table
                          )
  GROUP BY UserName;
```

To easily read the query and understand correlated subqueries, let's start from the inside. From the payments tables where the UserName is equal to the UserName in the outer query, grab the maximum amount. Now the outer query goes *row by row for each user* and compares whether that rows' amount is equal to that user's max amount, which is retrieved from the inner query. In other words, for each user the outer query goes row by row comparing its value to the inner query result.

## Benchmarking

A question that arose to me is, for this specific case, which method is faster? Let's try and answer it using a bit larger dataset.

```{r echo = TRUE}
payments_big <- data.frame(
  username = sample(c("Danny", "Alice", "Tom"), size = 2e3, replace = TRUE),
  payment_date = sample(seq(as.Date("2018/01/01"), as.Date("2021/08/01"), by = "day"), 2e3, replace = T),
  amount = sample.int(c(1e4), 2e3, replace = T)
)

glimpse(payments_big)
```

```{r eval= FALSE, echo = FALSE}
# Write table
# dbWriteTable(localhost_con, "payments_big", payments_big, overwrite = TRUE)
```


Great, a total of 1,000 rows for all the three users. Since we'll be benchmarking using R, let's write a function to evaluate the SQL queries:

Great. Using the above queries adapted for our 'payments_big' dataset, we'll benchmark the difference across all three:

```{r eval = FALSE}
Window_script <- "SELECT UserName, Payment_Date as 'Payment Date', amount
FROM (
  SELECT *,
    DENSE_RANK() OVER(Partition BY UserName Order by amount DESC) as rnk
  FROM payments_big) AS ranked_table
WHERE rnk = 1"

Join_script <- "SELECT DISTINCT p.UserName, p.payment_date, p.amount
FROM payments_big p
LEFT JOIN payments_big pp ON p.UserName = pp.UserName
  AND p.amount < pp.amount
WHERE pp.amount IS NULL"

Correlated_subquery_script <- "SELECT UserName,
  Payment_Date,
  amount
  FROM payments_big p
  WHERE amount = (SELECT MAX(amount)
                          FROM payments_big pp
                          WHERE pp.UserName = p.UserName -- Notice the relation to the parent table
                          )
  GROUP BY UserName;"
```


```{r eval = FALSE, echo = TRUE}
runquery <- function (x) dbGetQuery(localhost_con, x)

benchmarking <- microbenchmark::microbenchmark("Window function" = runquery(Window_script),
                                               "Join clause" = runquery(Join_script),
                                               "Correlated subquery" = runquery(Correlated_subquery_script),
                                               unit = "ms")
summary(benchmarking) %>% 
  mutate(across(is.numeric, function(x) round(x, 1))) %>% 
  gt() %>% 
  tab_options(table.align = 'center')
```

```{r echo=FALSE}
# saveRDS(benchmarking, "benchmark.Rds")
benchmarking <- readRDS("benchmark.Rds")

summary(benchmarking) %>% 
  mutate(across(is.numeric, function(x) round(x, 1))) %>% 
  gt() %>% 
  tab_options(table.align = 'center')
```



```{r echo=FALSE}
summary(benchmarking) %>% 
  mutate(across(is.numeric, function(x) round(x, 1))) %>% 
  gt() %>% 
  tab_options(table.align = 'center')
```

```{r}
theme_set(theme_minimal()+
            theme(
              plot.title.position = "plot",
              panel.grid.minor = element_blank()
          ))


ggplot(data = data.frame(expr = benchmarking$expr, time = benchmarking$time))+
  geom_boxplot(aes(x = fct_reorder(expr, time), y = time))+
  scale_y_continuous(name = "time (ms)\n",labels = function(x) x / 1e6)+
  labs(title = "Benchmarking the different solutions",
       x = NULL)
```


We can see that for the current question, the window function is most efficient. One ceaveat is that maybe something setsback when I query the local database through R, but if so I'd imagine it would affect all options.

The window function is best here, but I think knowing all apporaches can help you write better SQL. That is, sometimes one approach is a better fit to specific use case, without the ability / the relevancy of other instances. I definitely wrote a correlated subquery at work since it was the best fit (in terms of readability and as an immediate answer) given the specific problem I had at the time.

### Closing remarks

This was a pretty short post on some SQL approaches to solving a question. You can probably think of different approaches, or variants of the current ones. When contemplating this question I felt that it required me to utilize different SQL functions to solve the same question, so overall I'm glad I came across it. I didn't get the job but that's OK. Eventually that's how I ended up where I am today :)

Hope you find this useful and learned something new. Feel free to reach out and let me know of other solutions you thought of!  

```{r echo = FALSE}
# Close our SQL connection
dbDisconnect(localhost_con)
```

